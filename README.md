# LFM2-localAI
Quick chat interface with LFM2-700M and llama.cpp server
